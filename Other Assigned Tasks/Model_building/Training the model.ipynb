{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing required Libraries"
      ],
      "metadata": {
        "id": "7HCkW6Lt50az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy#for numerical analysis\n",
        "import tensorflow#open source ml tool by google\n"
      ],
      "metadata": {
        "id": "kh5XeNzd53VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist #mnist dataset\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "0G1lPoMk5_qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "ebRskMN06GuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "ygnTLpWa6KSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset"
      ],
      "metadata": {
        "id": "75VYWqEX6Nk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset is available in tensorflow dataset repository"
      ],
      "metadata": {
        "id": "3-T9zyV_6TsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
      ],
      "metadata": {
        "id": "CWc8q3Xv6PHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "XNm_HSbg6jqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(60000, 28, 28)\n",
        "(60000,)"
      ],
      "metadata": {
        "id": "mPPtHfkG6lNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Dataset has 60000 images & testing has 10000 images"
      ],
      "metadata": {
        "id": "XGIC4oSC6xS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "HvOf3Y6E6zp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(10000, 28, 28)\n",
        "(10000,)"
      ],
      "metadata": {
        "id": "NZ3ezJpB65qI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze the data"
      ],
      "metadata": {
        "id": "9d95ltD96-tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[3]"
      ],
      "metadata": {
        "id": "03el4_p27H5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0],\n",
        "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0],\n",
        "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0],\n",
        "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0],\n",
        "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0],\n",
        "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0, 124, 253, 255,  63,   0,   0,   0,   0,\n",
        "          0,   0],\n",
        "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,  96, 244, 251, 253,  62,   0,   0,   0,   0,\n",
        "          0,   0],"
      ],
      "metadata": {
        "id": "NZpjZOKy7JXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[3]"
      ],
      "metadata": {
        "id": "QRzElnfO7c5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1"
      ],
      "metadata": {
        "id": "R93d7DZ-7lZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "kS5nCw1-7pr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[3])"
      ],
      "metadata": {
        "id": "js86w5Lm7v1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "pl5ZjoD5716P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping the data"
      ],
      "metadata": {
        "id": "TIUPPimo78hA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ",As we are using Deep learning neural network, the input for this network to get trained on should be of higher dimensional. Our dataset is having three-dimensional images so we have to reshape them too higher dimensions"
      ],
      "metadata": {
        "id": "K7mXfE_h8BWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(batch,height,width,channel)\n",
        "x_train=x_train.reshape(60000,28,28,1).astype('float32')\n",
        "x_test=x_test.reshape(10000,28,28,1).astype('float32')"
      ],
      "metadata": {
        "id": "q26brO3A8LHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying one hot encoding"
      ],
      "metadata": {
        "id": "YS5OGgA98QeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One hot encoding to convert numerical values to classes where 0 to 9 are 10 seperate classes if value is 5 class 5 is 1 else 0"
      ],
      "metadata": {
        "id": "B4pj_cYk8VWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_classes=10\n",
        "y_train=np_utils.to_categorical(y_train,no_of_classes)\n",
        "y_test=np_utils.to_categorical(y_test,no_of_classes)"
      ],
      "metadata": {
        "id": "04dA5I0c8ZCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[3]"
      ],
      "metadata": {
        "id": "fD7qDd778df3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ],
      "metadata": {
        "id": "RkkRYvK88hBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add CNN Layers"
      ],
      "metadata": {
        "id": "MnC-71pD8k32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(64,(3,3),input_shape=(28,28,1),activation='relu'))\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(no_of_classes,activation='softmax'))"
      ],
      "metadata": {
        "id": "jG6Qf7DD8rJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "rfgmNss39Z23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3XLajY4N9bQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "fMxSQnJMBgh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=5,batch_size=32)"
      ],
      "metadata": {
        "id": "fGUNCUs9BkVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 1/5\n",
        "1875/1875 [==============================] - 237s 126ms/step - loss: 0.0667 - accuracy: 0.9801 - val_loss: 0.0696 - val_accuracy: 0.9788\n",
        "Epoch 2/5\n",
        "1875/1875 [==============================] - 241s 128ms/step - loss: 0.0492 - accuracy: 0.9844 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
        "Epoch 3/5\n",
        "1875/1875 [==============================] - 214s 114ms/step - loss: 0.0356 - accuracy: 0.9896 - val_loss: 0.0872 - val_accuracy: 0.9791\n",
        "Epoch 4/5\n",
        "1875/1875 [==============================] - 204s 109ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.1150 - val_accuracy: 0.9766\n",
        "Epoch 5/5\n",
        "1875/1875 [==============================] - 202s 108ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.1600 - val_accuracy: 0.9703\n"
      ],
      "metadata": {
        "id": "RsdmV7YOBrSi"
      }
    }
  ]
}